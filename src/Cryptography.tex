\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%

\def\useItalian{0}  % 1 = Italian, 0 = English

\def\courseName{Cryptography}

\def\coursePrerequisites{TODO}

% \def\book{"My book",\\Author 1, ...}

% \def\authorName{Simone Bianco}
% \def\email{bianco.simone@outlook.it}
% \def\github{https://github.com/Exyss/university-notes}
% \def\linkedin{https://www.linkedin.com/in/simone-bianco}

\def\authorName{Alessio Bandiera}
\def\email{alessio.bandiera02@gmail.com}
\def\github{https://github.com/aflaag-notes}
\def\linkedin{https://www.linkedin.com/in/alessio-bandiera-a53767223}

% Do not change

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../packages/Nyx/nyx-packages}
\usepackage{../../packages/Nyx/nyx-styles}
\usepackage{../../packages/Nyx/nyx-frames}
\usepackage{../../packages/Nyx/nyx-macros}
\usepackage{../../packages/Nyx/nyx-title}
\usepackage{../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../packages/Nyx/logo.png}

\if\useItalian1
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} Universit√† di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    \ifdefined\book
        \subtitle{Appunti integrati con il libro \book}
    \fi
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \ifdefined\book
        \subtitle{Lecture notes integrated with the book \book}
    \fi
    \author{\textit{Author}\\\authorName}
\fi

\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

\addbibresource{./references.bib}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
\maketitle

% The following style changes are valid only inside this scope 
{
	\hypersetup{allcolors=black}
	\fancypagestyle{plain}{%
		\fancyhead{}        % clear all header fields
		\fancyfoot{}        % clear all header fields
		\fancyfoot[C]{\thepage}
		\renewcommand{\headrulewidth}{0pt}
		\renewcommand{\footrulewidth}{0pt}}

	\romantableofcontents
}

\introduction

%%%%%%%%%%%%%%%%%%%%%

\chapter{TODO}

\section{TODO}

TODO \todo{missing introduction}

\begin{frameddefn}{Perfect secrecy}
	Given any distribution $M$ over $\mathcal M$, and $k$ chosen UAR on $\mathcal K$, we say that $\Pi = (\mathrm{Enc}, \mathrm{Dec})$ is \tbf{perfectly secret} if $$\forall m \in \mathcal M, c \in \mathcal C \quad \Pr[M = m] = \Pr[M = m \mid C = c]$$
\end{frameddefn}

TODO \todo{de sta definizione non me torna la distribuzione} In other words, this definition requires the encrypted text $c$ to \tit{not reveal} anything about the plaintext $m$. The following lemma shows some properties about perfect secrecy.

\begin{framedlem}{}
	The following three conditions are equivalent:

	\begin{enumerate}
		\item perfect secrecy
		\item independence of $M$ and $C$
		\item $\forall m, m' \in \mathcal M, c \in C \quad \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m) = c] = \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m') = c]$
	\end{enumerate}
\end{framedlem}

\begin{proof}
	We will prove the statements cyclically.

	\begin{itemize}
		\item $1 \implies 2$. By perfect secrecy, we have that $$\Pr[M = m] = \Pr[M = m \mid C = c] = \dfrac{\Pr[M = m \land C = c]}{\Pr[C = c]}$$ therefore, by rearranging the terms we get that $$\Pr[M = m \land C = c] = \Pr[M = m] \cdot \Pr[C = c]$$
		\item $2 \implies 3$. Fix $m \in \mathcal M$ and $c \in \mathcal C$; we have that

		      \begin{equation*}
			      \begin{alignedat}{2}
				      \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m) = c] & = \Pr_{k \in \mathcal K}[\mathrm{Enc}(K, M) \mid M = m] &                                                     \\
				                                                     & = \Pr_{k \in \mathcal K}[C = c \mid M = m]              & \quad \quad (\mbox{by definition})                  \\
				                                                     & = \Pr[C = c]                                            & \quad \quad (\mbox{by independence of $M$ and $C$})
			      \end{alignedat}
		      \end{equation*}

		      Now fix another message $m' \in \mathcal M$; we can repeat the same steps and obtain that $\Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m') = c] = \Pr[C = c]$ which concludes the proof.
		\item $3 \implies 1$. Fix $c \in \mathcal C$.

		      \claim{
			      $\Pr[C = c] = \Pr[C = c \mid M = m]$
		      }{
			      By assuming property 3, we get that

			      \begin{equation*}
				      \begin{alignedat}{2}
					      \Pr[C = c] & = \sum_{m' \in \mathcal M}{\Pr[C = c \mid M = m'] \cdot \Pr[M = m']}                                     & \quad (\mbox{by the L.T.P.}) \\
					                 & = \sum_{m' \in \mathcal M}{\Pr_{k \in \mathcal K}[\mathrm{Enc}(k, M) = c \mid M = m'] \cdot \Pr[M = m']} &                              \\
					                 & = \sum_{m' \in \mathcal M}{\Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m') = c] \cdot \Pr[M = m']}            &                              \\
					                 & = \sum_{m' \in \mathcal M}{\Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m) = c] \cdot \Pr[M = m']}             & \quad (\mbox{by property 3}) \\
					                 & = \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m) = c] \cdot \sum_{m' \in \mathcal M}{\Pr[m = m']}             &                              \\
					                 & = \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, m) = c]                                                         &                              \\
					                 & = \Pr_{k \in \mathcal K}[\mathrm{Enc}(k, M) = c \mid M = m]                                              &                              \\
					                 & = \Pr_{k \in \mathcal K}[C = c \mid M = m]                                                               &                              \\
				      \end{alignedat}
			      \end{equation*}
		      }

		      Finally, by Bayes' theorem we have that

		      \begin{equation*}
			      \begin{alignedat}{2}
				      \Pr[M = m] & = \dfrac{\Pr[M = m \mid C = c] \cdot \Pr[C = c]}{\Pr[C = c \mid M = m]} &                             \\
				                 & = \Pr[M = m \mid C = c]                                                 & \quad (\mbox{by the claim}) \\
			      \end{alignedat}
		      \end{equation*}

		      which is precisely perfect secrecy.
	\end{itemize}
\end{proof}

Thanks to this lemma, we can prove the following result through the third alternative definition of perfect secrecy.

\begin{frameddthm}{}
    OTP has perfect secrecy.
\end{framedthm}

\begin{proof}
    % Fix two messages $m, m' \in \mathcal M$, and a cyphertext $c \in \mathcal C$; by the definition of the OTP system and the properties of the XOR function, we have that $$\Pr_{K \in_R \mathcal K}[\mathrm{Enc}(K, m) = c] = \Pr_{K \in_R \mathcal K}[K \oplus m = c]$$
    TODO \todo{prima fai OTP magari}
\end{proof}

TODO \todo{buco}

We will now focus on the second goal of cryptography: \tit{message integrity}, which is usually achieved through \tbf{Message Authentication Codes (MACs)}, which allows the receiver to determine if the message has been tempered with.

First, let's start with a simple model, that ignores secrecy and only cares about message integrity. This type of MACs use a deterministic \tbf{tagging function}, usually implemented though \tit{hash functions}, but in general it is a function of the form $$\func{\mbox{Tag}}{\mathcal K \times \mathcal M}{\mathcal T}$$, whetre $\mathcal T$ is the tag space, i.e. the set of all tag strings.

TODO \todo{disegno + paragrafo}

\begin{frameddefn}{$t$-time $\varepsilon$-statistical security}
    A MAC $\Pi = (\mbox{Tag})$ is said to have \tbf{$t$-time $\varepsilon$-statistical security} if $\forall m, m_1, \ldots, m_t \in \mathcal M$ pairwise distinct, and $\forall \tau, \tau_1, \ldots, \tau_t \in \mathcal T$ it holds that $$\Pr_{K \in_R \mathcal K}[\mbox{Tag}(K, m) = \tau \mid \mbox{Tag}(K, m_1) = \tau_1, \ldots, \mbox{Tag}(K, m_t) = \tau_t] \le \varepsilon$$
\end{frameddefn}
 
In other words, this property states that even when $t$ message-tag pairs $(m_1, \tau_1), \ldots, (m_t, \tau_t)$ obtained through the same key $K$ are known, the probability of any message-tag pair $(m, \tau)$ being obtained through the same key $K$ is at most $\varepsilon$. Clearly, we would like $\varepsilon$ to be as small as possible, and $t$ to be as large as possible. However it is easy to see that $\forall t \in \N$ it is impossible to get $\varepsilon = 0$, since any random $\tau \in \mathcal T$ has always a $\tfrac{1}{\abs {\mathcal T}}$ probability of being correct by random chance.

Furthermore, as we proved for perfect secrecy, we are going to show that the notion of \curlyquotes{good} statistical security is achievable, even though it's highly inefficient in terms of key size.

\begin{framedthm}{}
    Any $t$-time $2^{-\lambda}$-statistically secure MAC must have a key of size $(t + 1) \cdot \lambda$
\end{framedthm}

A good enough 1-time statisticalllhy secure MAC can be achieved through \tbf{pairwise independent hash functions}, a family of hash functions where each pair of functions forms a pari of independent random variables.

\begin{frameddefn}{Pairwise independency}
    Let $\mathcal H = \{h_K : \mathcal K \to \mathcal T\}_{K \in_R \mathcal K}$ be a family of hash functions; we say that $\mathcal H$ is \tbf{pairwise independent} if $\forall m, m' \in \mathcal M$ such that $m \neq m'$ it holds that the distribution $(h_K(m), h_K(m'))$ is uniform over $\mathcal T \times \mathcal T$ when $K \in_R \mathcal K$
\end{frameddefn}

Note that, in this definition, $h_K(m)$ and $h_K(m')$ are two random variables \todo{what the f does this def mean}.

\begin{framedthm}{}
    Any $\mathcal H = \{h_K : \mathcal M \to \mathcal T\}_{K \in_R \mathcal K}$ family of pairwise independent hash functions induces a 1-time $\tfrac{1}{\abs {\mathcal T}}$-statistically secure MAC.
\end{framedthm}

\begin{proof}
    TODO \todo{todo}
\end{proof}

TODO \todo{buco}

\subsection{Randomness extraction}

TODO \todo{buco}

Let's first address the problem of \tit{extracting} randomness from an unpredictable secure source (i.e. random variable) $X$. The first \tbf{extractor} has been introduced by Von Neumann, which yields a fair random coin from an unpredictable unfair one. Let $B \in \{0, 1\}$ be the random variable describing the unpredictable unfrair coin, such that for instance $\Pr[B = 0] = p < \tfrac{1}{2}$. Let $Y \in \{0, 1\}$ be the random variable describing the coin we want to extract; its vaule will be determined by the following procedure:

\begin{itemize}
    \item sample two values $b_1, b_2$ from $B$ independently
    \item if $b_1 = b_2$, $Y$ is assigned no value --- noted with $Y = ?$ and the process is repeated from the beginning
    \item if $b_1 \neq b_2$, $Y = 1$ if and only if $b_1 = 0$ and $b_2 = 1$
\end{itemize}

First, we observe that this process can go on indefinitely, never halting on any value for $Y$. But assuming the procedure does halt, we have that $$\Pr[Y = 0] = \Pr[b_1 = 1 \land b_2 = 0] = \Pr[b_1 = 1] \cdot \Pr[b_2 = 0] = (1 - p)p$$ $$\Pr[Y = 1] = \Pr[b_1 = 0 \land b_2 = 1] = \Pr[b_1 = 0] \cdot \Pr[b_2 = 1] = p(1 - p)$$ Moreover, we see that the probability of $Y = ?$ happening for $m$ consecutive tries is at most $$\Pr[Y = ? \mbox{for $m$ tries}] = (\Pr[Y = ?])^m = (1 - \Pr[Y = 0 \lor Y = 1])^m \le (1 - 2p(1 - p))^m$$ and as $m$ goes to infinity, the latter probabijlity goes to 0, which implies that $\Pr[Y = 0]$ and $\Pr[Y = 1]$ will tend towards $\tfrac{1}{2}$ due to them having the same probability and them being the only two possible outcomes. Thus, we have achieved a fair coin $Y$.

TODO \todo{par}

\begin{frameddefn}{Min-entropy}
    Given a random variable $X$, the \tbf{min-entropy} of $X$ is defined as follows: $$H_\mbox{min}(X) := - \log \max_x{\Pr[X = x]}$$
\end{frameddefn}

TODO \todo{todo}

\begin{framedprop}{}
    Let $X$ be a random variable defined over $\{0, 1\}^n$; there is no extractor Ext such that $\mbox{Ext}(X) \in \{0, 1\}$.
\end{framedprop}

\begin{proof}
    Let $\func{\mbox{Ext}}{\{0, 1\}^n}{\{0, 1\}}$ be any extractor, and let $b \in \{0, 1\}$ be the output minimizing the cardinality of the preimage of the extractor, i.e. the set of inputs for which the extractor output $b$ $$b = \argmin_{b' \in \{0, 1\}}{\abs{\mbox{Ext}^{-1}(b)}}$$ By the pigeonhole principle, we have that $$\abs{\mbox{Ext}^{-1}(b)} \le \dfrac{\abs{\{0, 1\}^n}}{2} = \dfrac{2^n}{2} = 2^{n - 1}$$ Let $X$ be a random variable uniform over $\mbox{Ext}^{-1}(b)$ \todo{da finire}
\end{proof}

% \printbibliography % UNCOMMENT FOR BIBLIOGRAPHY

\end{document}
